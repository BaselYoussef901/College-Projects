{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "model=YOLO('yolov5su.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.16 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.10  Python-3.11.5 torch-2.3.0+cpu CPU (11th Gen Intel Core(TM) i5-11320H 3.20GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov5su.pt, data=datav5.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train2\n",
      "Overriding model.yaml nc=80 with nc=8\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \n",
      " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \n",
      " 24        [17, 20, 23]  1   2119144  ultralytics.nn.modules.head.Detect           [8, [128, 256, 512]]          \n",
      "YOLOv5s summary: 262 layers, 9125288 parameters, 9125272 gradients, 24.1 GFLOPs\n",
      "\n",
      "Transferred 421/427 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train2', view at http://localhost:6006/\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Mahmoud\\Downloads\\yolov5\\KITTI-3\\train\\labels.cache... 4723 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4723/4723 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Mahmoud\\Downloads\\yolov5\\KITTI-3\\valid\\labels.cache... 1495 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1495/1495 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train2\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000833, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train2\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10         0G      1.329      1.615      1.219          9        640: 100%|██████████| 296/296 [1:44:29<00:00, 21.18s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [10:00<00:00, 12.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1495       8018      0.557       0.41      0.428      0.254\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10         0G      1.206       1.05      1.162         11        640: 100%|██████████| 296/296 [1:34:13<00:00, 19.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [09:51<00:00, 12.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1495       8018      0.562      0.442      0.461       0.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10         0G      1.177      0.966      1.157          7        640: 100%|██████████| 296/296 [2:06:04<00:00, 25.56s/it]   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [10:01<00:00, 12.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1495       8018      0.596      0.443      0.482      0.282\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10         0G      1.132     0.9015      1.136         13        640: 100%|██████████| 296/296 [1:37:11<00:00, 19.70s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [10:47<00:00, 13.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1495       8018      0.626      0.534      0.578      0.354\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10         0G      1.083     0.8256      1.108          8        640: 100%|██████████| 296/296 [1:44:12<00:00, 21.12s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [12:03<00:00, 15.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1495       8018      0.676      0.582       0.65      0.408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10         0G      1.032     0.7607      1.082         23        640: 100%|██████████| 296/296 [1:45:35<00:00, 21.40s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [10:40<00:00, 13.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1495       8018      0.728      0.653      0.715      0.463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10         0G     0.9936     0.7071      1.065          2        640: 100%|██████████| 296/296 [1:41:33<00:00, 20.59s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [10:37<00:00, 13.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1495       8018       0.77      0.664      0.756      0.495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10         0G     0.9484     0.6591      1.043         20        640: 100%|██████████| 296/296 [1:45:39<00:00, 21.42s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [10:38<00:00, 13.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1495       8018      0.789      0.701      0.776      0.521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10         0G     0.9111     0.6212      1.026         13        640: 100%|██████████| 296/296 [1:49:28<00:00, 22.19s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [12:00<00:00, 15.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1495       8018      0.851      0.725       0.81      0.545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10         0G     0.8764     0.5848      1.009         31        640: 100%|██████████| 296/296 [1:44:40<00:00, 21.22s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [10:37<00:00, 13.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1495       8018      0.814      0.746      0.821      0.566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 19.358 hours.\n",
      "Optimizer stripped from runs\\detect\\train2\\weights\\last.pt, 18.5MB\n",
      "Optimizer stripped from runs\\detect\\train2\\weights\\best.pt, 18.5MB\n",
      "\n",
      "Validating runs\\detect\\train2\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.10  Python-3.11.5 torch-2.3.0+cpu CPU (11th Gen Intel Core(TM) i5-11320H 3.20GHz)\n",
      "YOLOv5s summary (fused): 193 layers, 9114632 parameters, 0 gradients, 23.8 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [08:27<00:00, 10.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1495       8018      0.812      0.748      0.821      0.566\n",
      "                   Car       1495       5627      0.859      0.934      0.961      0.775\n",
      "               Cyclist       1495        330      0.781      0.691      0.766      0.457\n",
      "                  Misc       1495        196      0.889      0.684      0.775      0.548\n",
      "            Pedestrian       1495        905       0.81      0.617       0.75       0.39\n",
      "        Person_sitting       1495         52      0.737      0.378      0.579      0.297\n",
      "                  Tram       1495        113      0.735      0.876      0.885      0.623\n",
      "                 Truck       1495        230        0.9       0.94      0.958      0.762\n",
      "                   Van       1495        565      0.788      0.862      0.893      0.674\n",
      "Speed: 4.9ms preprocess, 324.2ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results=model.train(data='datav5.yaml',epochs=10,batch=16,imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Mahmoud\\Downloads\\yolov5\\KITTI-3\\test\\images\\000031_png.rf.00bed1c0235cba9dd15b5467bf965206.jpg: 640x640 7 Cars, 1 Truck, 2 Vans, 264.2ms\n",
      "Speed: 3.7ms preprocess, 264.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model=YOLO(r'C:\\Users\\Mahmoud\\Downloads\\yolov5\\runs\\detect\\data train\\train1\\weights\\last.pt')\n",
    "model=YOLO(r'C:\\Users\\Mahmoud\\Downloads\\yolov5\\runs\\detect\\data train\\train1\\weights\\best.pt')\n",
    "results=model(r'C:\\Users\\Mahmoud\\Downloads\\yolov5\\KITTI-3\\test\\images\\000031_png.rf.00bed1c0235cba9dd15b5467bf965206.jpg',save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.0.conv.weight\n",
      "model.0.bn.weight\n",
      "model.0.bn.bias\n",
      "model.1.conv.weight\n",
      "model.1.bn.weight\n",
      "model.1.bn.bias\n",
      "model.2.cv1.conv.weight\n",
      "model.2.cv1.bn.weight\n",
      "model.2.cv1.bn.bias\n",
      "model.2.cv2.conv.weight\n",
      "model.2.cv2.bn.weight\n",
      "model.2.cv2.bn.bias\n",
      "model.2.cv3.conv.weight\n",
      "model.2.cv3.bn.weight\n",
      "model.2.cv3.bn.bias\n",
      "model.2.m.0.cv1.conv.weight\n",
      "model.2.m.0.cv1.bn.weight\n",
      "model.2.m.0.cv1.bn.bias\n",
      "model.2.m.0.cv2.conv.weight\n",
      "model.2.m.0.cv2.bn.weight\n",
      "model.2.m.0.cv2.bn.bias\n",
      "model.3.conv.weight\n",
      "model.3.bn.weight\n",
      "model.3.bn.bias\n",
      "model.4.cv1.conv.weight\n",
      "model.4.cv1.bn.weight\n",
      "model.4.cv1.bn.bias\n",
      "model.4.cv2.conv.weight\n",
      "model.4.cv2.bn.weight\n",
      "model.4.cv2.bn.bias\n",
      "model.4.cv3.conv.weight\n",
      "model.4.cv3.bn.weight\n",
      "model.4.cv3.bn.bias\n",
      "model.4.m.0.cv1.conv.weight\n",
      "model.4.m.0.cv1.bn.weight\n",
      "model.4.m.0.cv1.bn.bias\n",
      "model.4.m.0.cv2.conv.weight\n",
      "model.4.m.0.cv2.bn.weight\n",
      "model.4.m.0.cv2.bn.bias\n",
      "model.4.m.1.cv1.conv.weight\n",
      "model.4.m.1.cv1.bn.weight\n",
      "model.4.m.1.cv1.bn.bias\n",
      "model.4.m.1.cv2.conv.weight\n",
      "model.4.m.1.cv2.bn.weight\n",
      "model.4.m.1.cv2.bn.bias\n",
      "model.5.conv.weight\n",
      "model.5.bn.weight\n",
      "model.5.bn.bias\n",
      "model.6.cv1.conv.weight\n",
      "model.6.cv1.bn.weight\n",
      "model.6.cv1.bn.bias\n",
      "model.6.cv2.conv.weight\n",
      "model.6.cv2.bn.weight\n",
      "model.6.cv2.bn.bias\n",
      "model.6.cv3.conv.weight\n",
      "model.6.cv3.bn.weight\n",
      "model.6.cv3.bn.bias\n",
      "model.6.m.0.cv1.conv.weight\n",
      "model.6.m.0.cv1.bn.weight\n",
      "model.6.m.0.cv1.bn.bias\n",
      "model.6.m.0.cv2.conv.weight\n",
      "model.6.m.0.cv2.bn.weight\n",
      "model.6.m.0.cv2.bn.bias\n",
      "model.6.m.1.cv1.conv.weight\n",
      "model.6.m.1.cv1.bn.weight\n",
      "model.6.m.1.cv1.bn.bias\n",
      "model.6.m.1.cv2.conv.weight\n",
      "model.6.m.1.cv2.bn.weight\n",
      "model.6.m.1.cv2.bn.bias\n",
      "model.6.m.2.cv1.conv.weight\n",
      "model.6.m.2.cv1.bn.weight\n",
      "model.6.m.2.cv1.bn.bias\n",
      "model.6.m.2.cv2.conv.weight\n",
      "model.6.m.2.cv2.bn.weight\n",
      "model.6.m.2.cv2.bn.bias\n",
      "model.7.conv.weight\n",
      "model.7.bn.weight\n",
      "model.7.bn.bias\n",
      "model.8.cv1.conv.weight\n",
      "model.8.cv1.bn.weight\n",
      "model.8.cv1.bn.bias\n",
      "model.8.cv2.conv.weight\n",
      "model.8.cv2.bn.weight\n",
      "model.8.cv2.bn.bias\n",
      "model.8.cv3.conv.weight\n",
      "model.8.cv3.bn.weight\n",
      "model.8.cv3.bn.bias\n",
      "model.8.m.0.cv1.conv.weight\n",
      "model.8.m.0.cv1.bn.weight\n",
      "model.8.m.0.cv1.bn.bias\n",
      "model.8.m.0.cv2.conv.weight\n",
      "model.8.m.0.cv2.bn.weight\n",
      "model.8.m.0.cv2.bn.bias\n",
      "model.9.cv1.conv.weight\n",
      "model.9.cv1.bn.weight\n",
      "model.9.cv1.bn.bias\n",
      "model.9.cv2.conv.weight\n",
      "model.9.cv2.bn.weight\n",
      "model.9.cv2.bn.bias\n",
      "model.10.conv.weight\n",
      "model.10.bn.weight\n",
      "model.10.bn.bias\n",
      "model.13.cv1.conv.weight\n",
      "model.13.cv1.bn.weight\n",
      "model.13.cv1.bn.bias\n",
      "model.13.cv2.conv.weight\n",
      "model.13.cv2.bn.weight\n",
      "model.13.cv2.bn.bias\n",
      "model.13.cv3.conv.weight\n",
      "model.13.cv3.bn.weight\n",
      "model.13.cv3.bn.bias\n",
      "model.13.m.0.cv1.conv.weight\n",
      "model.13.m.0.cv1.bn.weight\n",
      "model.13.m.0.cv1.bn.bias\n",
      "model.13.m.0.cv2.conv.weight\n",
      "model.13.m.0.cv2.bn.weight\n",
      "model.13.m.0.cv2.bn.bias\n",
      "model.14.conv.weight\n",
      "model.14.bn.weight\n",
      "model.14.bn.bias\n",
      "model.17.cv1.conv.weight\n",
      "model.17.cv1.bn.weight\n",
      "model.17.cv1.bn.bias\n",
      "model.17.cv2.conv.weight\n",
      "model.17.cv2.bn.weight\n",
      "model.17.cv2.bn.bias\n",
      "model.17.cv3.conv.weight\n",
      "model.17.cv3.bn.weight\n",
      "model.17.cv3.bn.bias\n",
      "model.17.m.0.cv1.conv.weight\n",
      "model.17.m.0.cv1.bn.weight\n",
      "model.17.m.0.cv1.bn.bias\n",
      "model.17.m.0.cv2.conv.weight\n",
      "model.17.m.0.cv2.bn.weight\n",
      "model.17.m.0.cv2.bn.bias\n",
      "model.18.conv.weight\n",
      "model.18.bn.weight\n",
      "model.18.bn.bias\n",
      "model.20.cv1.conv.weight\n",
      "model.20.cv1.bn.weight\n",
      "model.20.cv1.bn.bias\n",
      "model.20.cv2.conv.weight\n",
      "model.20.cv2.bn.weight\n",
      "model.20.cv2.bn.bias\n",
      "model.20.cv3.conv.weight\n",
      "model.20.cv3.bn.weight\n",
      "model.20.cv3.bn.bias\n",
      "model.20.m.0.cv1.conv.weight\n",
      "model.20.m.0.cv1.bn.weight\n",
      "model.20.m.0.cv1.bn.bias\n",
      "model.20.m.0.cv2.conv.weight\n",
      "model.20.m.0.cv2.bn.weight\n",
      "model.20.m.0.cv2.bn.bias\n",
      "model.21.conv.weight\n",
      "model.21.bn.weight\n",
      "model.21.bn.bias\n",
      "model.23.cv1.conv.weight\n",
      "model.23.cv1.bn.weight\n",
      "model.23.cv1.bn.bias\n",
      "model.23.cv2.conv.weight\n",
      "model.23.cv2.bn.weight\n",
      "model.23.cv2.bn.bias\n",
      "model.23.cv3.conv.weight\n",
      "model.23.cv3.bn.weight\n",
      "model.23.cv3.bn.bias\n",
      "model.23.m.0.cv1.conv.weight\n",
      "model.23.m.0.cv1.bn.weight\n",
      "model.23.m.0.cv1.bn.bias\n",
      "model.23.m.0.cv2.conv.weight\n",
      "model.23.m.0.cv2.bn.weight\n",
      "model.23.m.0.cv2.bn.bias\n",
      "model.24.cv2.0.0.conv.weight\n",
      "model.24.cv2.0.0.bn.weight\n",
      "model.24.cv2.0.0.bn.bias\n",
      "model.24.cv2.0.1.conv.weight\n",
      "model.24.cv2.0.1.bn.weight\n",
      "model.24.cv2.0.1.bn.bias\n",
      "model.24.cv2.0.2.weight\n",
      "model.24.cv2.0.2.bias\n",
      "model.24.cv2.1.0.conv.weight\n",
      "model.24.cv2.1.0.bn.weight\n",
      "model.24.cv2.1.0.bn.bias\n",
      "model.24.cv2.1.1.conv.weight\n",
      "model.24.cv2.1.1.bn.weight\n",
      "model.24.cv2.1.1.bn.bias\n",
      "model.24.cv2.1.2.weight\n",
      "model.24.cv2.1.2.bias\n",
      "model.24.cv2.2.0.conv.weight\n",
      "model.24.cv2.2.0.bn.weight\n",
      "model.24.cv2.2.0.bn.bias\n",
      "model.24.cv2.2.1.conv.weight\n",
      "model.24.cv2.2.1.bn.weight\n",
      "model.24.cv2.2.1.bn.bias\n",
      "model.24.cv2.2.2.weight\n",
      "model.24.cv2.2.2.bias\n",
      "model.24.cv3.0.0.conv.weight\n",
      "model.24.cv3.0.0.bn.weight\n",
      "model.24.cv3.0.0.bn.bias\n",
      "model.24.cv3.0.1.conv.weight\n",
      "model.24.cv3.0.1.bn.weight\n",
      "model.24.cv3.0.1.bn.bias\n",
      "model.24.cv3.0.2.weight\n",
      "model.24.cv3.0.2.bias\n",
      "model.24.cv3.1.0.conv.weight\n",
      "model.24.cv3.1.0.bn.weight\n",
      "model.24.cv3.1.0.bn.bias\n",
      "model.24.cv3.1.1.conv.weight\n",
      "model.24.cv3.1.1.bn.weight\n",
      "model.24.cv3.1.1.bn.bias\n",
      "model.24.cv3.1.2.weight\n",
      "model.24.cv3.1.2.bias\n",
      "model.24.cv3.2.0.conv.weight\n",
      "model.24.cv3.2.0.bn.weight\n",
      "model.24.cv3.2.0.bn.bias\n",
      "model.24.cv3.2.1.conv.weight\n",
      "model.24.cv3.2.1.bn.weight\n",
      "model.24.cv3.2.1.bn.bias\n",
      "model.24.cv3.2.2.weight\n",
      "model.24.cv3.2.2.bias\n",
      "model.24.dfl.conv.weight\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO('yolov5su.pt')\n",
    "for name, param in model.model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer model.0.conv.weight is frozen.\n",
      "Layer model.0.bn.weight is frozen.\n",
      "Layer model.0.bn.bias is frozen.\n",
      "Layer model.1.conv.weight is frozen.\n",
      "Layer model.1.bn.weight is frozen.\n",
      "Layer model.1.bn.bias is frozen.\n",
      "Layer model.2.cv1.conv.weight is frozen.\n",
      "Layer model.2.cv1.bn.weight is frozen.\n",
      "Layer model.2.cv1.bn.bias is frozen.\n",
      "Layer model.2.cv2.conv.weight is frozen.\n",
      "Layer model.2.cv2.bn.weight is frozen.\n",
      "Layer model.2.cv2.bn.bias is frozen.\n",
      "Layer model.2.cv3.conv.weight is frozen.\n",
      "Layer model.2.cv3.bn.weight is frozen.\n",
      "Layer model.2.cv3.bn.bias is frozen.\n",
      "Layer model.2.m.0.cv1.conv.weight is frozen.\n",
      "Layer model.2.m.0.cv1.bn.weight is frozen.\n",
      "Layer model.2.m.0.cv1.bn.bias is frozen.\n",
      "Layer model.2.m.0.cv2.conv.weight is frozen.\n",
      "Layer model.2.m.0.cv2.bn.weight is frozen.\n",
      "Layer model.2.m.0.cv2.bn.bias is frozen.\n",
      "Layer model.3.conv.weight is frozen.\n",
      "Layer model.3.bn.weight is frozen.\n",
      "Layer model.3.bn.bias is frozen.\n",
      "Layer model.4.cv1.conv.weight is frozen.\n",
      "Layer model.4.cv1.bn.weight is frozen.\n",
      "Layer model.4.cv1.bn.bias is frozen.\n",
      "Layer model.4.cv2.conv.weight is frozen.\n",
      "Layer model.4.cv2.bn.weight is frozen.\n",
      "Layer model.4.cv2.bn.bias is frozen.\n",
      "Layer model.4.cv3.conv.weight is frozen.\n",
      "Layer model.4.cv3.bn.weight is frozen.\n",
      "Layer model.4.cv3.bn.bias is frozen.\n",
      "Layer model.4.m.0.cv1.conv.weight is frozen.\n",
      "Layer model.4.m.0.cv1.bn.weight is frozen.\n",
      "Layer model.4.m.0.cv1.bn.bias is frozen.\n",
      "Layer model.4.m.0.cv2.conv.weight is frozen.\n",
      "Layer model.4.m.0.cv2.bn.weight is frozen.\n",
      "Layer model.4.m.0.cv2.bn.bias is frozen.\n",
      "Layer model.4.m.1.cv1.conv.weight is frozen.\n",
      "Layer model.4.m.1.cv1.bn.weight is frozen.\n",
      "Layer model.4.m.1.cv1.bn.bias is frozen.\n",
      "Layer model.4.m.1.cv2.conv.weight is frozen.\n",
      "Layer model.4.m.1.cv2.bn.weight is frozen.\n",
      "Layer model.4.m.1.cv2.bn.bias is frozen.\n",
      "Layer model.5.conv.weight is frozen.\n",
      "Layer model.5.bn.weight is frozen.\n",
      "Layer model.5.bn.bias is frozen.\n",
      "Layer model.6.cv1.conv.weight is frozen.\n",
      "Layer model.6.cv1.bn.weight is frozen.\n",
      "Layer model.6.cv1.bn.bias is frozen.\n",
      "Layer model.6.cv2.conv.weight is frozen.\n",
      "Layer model.6.cv2.bn.weight is frozen.\n",
      "Layer model.6.cv2.bn.bias is frozen.\n",
      "Layer model.6.cv3.conv.weight is frozen.\n",
      "Layer model.6.cv3.bn.weight is frozen.\n",
      "Layer model.6.cv3.bn.bias is frozen.\n",
      "Layer model.6.m.0.cv1.conv.weight is frozen.\n",
      "Layer model.6.m.0.cv1.bn.weight is frozen.\n",
      "Layer model.6.m.0.cv1.bn.bias is frozen.\n",
      "Layer model.6.m.0.cv2.conv.weight is frozen.\n",
      "Layer model.6.m.0.cv2.bn.weight is frozen.\n",
      "Layer model.6.m.0.cv2.bn.bias is frozen.\n",
      "Layer model.6.m.1.cv1.conv.weight is frozen.\n",
      "Layer model.6.m.1.cv1.bn.weight is frozen.\n",
      "Layer model.6.m.1.cv1.bn.bias is frozen.\n",
      "Layer model.6.m.1.cv2.conv.weight is frozen.\n",
      "Layer model.6.m.1.cv2.bn.weight is frozen.\n",
      "Layer model.6.m.1.cv2.bn.bias is frozen.\n",
      "Layer model.6.m.2.cv1.conv.weight is frozen.\n",
      "Layer model.6.m.2.cv1.bn.weight is frozen.\n",
      "Layer model.6.m.2.cv1.bn.bias is frozen.\n",
      "Layer model.6.m.2.cv2.conv.weight is frozen.\n",
      "Layer model.6.m.2.cv2.bn.weight is frozen.\n",
      "Layer model.6.m.2.cv2.bn.bias is frozen.\n",
      "Layer model.7.conv.weight is frozen.\n",
      "Layer model.7.bn.weight is frozen.\n",
      "Layer model.7.bn.bias is frozen.\n",
      "Layer model.8.cv1.conv.weight is frozen.\n",
      "Layer model.8.cv1.bn.weight is frozen.\n",
      "Layer model.8.cv1.bn.bias is frozen.\n",
      "Layer model.8.cv2.conv.weight is frozen.\n",
      "Layer model.8.cv2.bn.weight is frozen.\n",
      "Layer model.8.cv2.bn.bias is frozen.\n",
      "Layer model.8.cv3.conv.weight is frozen.\n",
      "Layer model.8.cv3.bn.weight is frozen.\n",
      "Layer model.8.cv3.bn.bias is frozen.\n",
      "Layer model.8.m.0.cv1.conv.weight is frozen.\n",
      "Layer model.8.m.0.cv1.bn.weight is frozen.\n",
      "Layer model.8.m.0.cv1.bn.bias is frozen.\n",
      "Layer model.8.m.0.cv2.conv.weight is frozen.\n",
      "Layer model.8.m.0.cv2.bn.weight is frozen.\n",
      "Layer model.8.m.0.cv2.bn.bias is frozen.\n",
      "Layer model.9.cv1.conv.weight is frozen.\n",
      "Layer model.9.cv1.bn.weight is frozen.\n",
      "Layer model.9.cv1.bn.bias is frozen.\n",
      "Layer model.9.cv2.conv.weight is frozen.\n",
      "Layer model.9.cv2.bn.weight is frozen.\n",
      "Layer model.9.cv2.bn.bias is frozen.\n",
      "Layer model.10.conv.weight is frozen.\n",
      "Layer model.10.bn.weight is frozen.\n",
      "Layer model.10.bn.bias is frozen.\n",
      "Layer model.13.cv1.conv.weight is frozen.\n",
      "Layer model.13.cv1.bn.weight is frozen.\n",
      "Layer model.13.cv1.bn.bias is frozen.\n",
      "Layer model.13.cv2.conv.weight is frozen.\n",
      "Layer model.13.cv2.bn.weight is frozen.\n",
      "Layer model.13.cv2.bn.bias is frozen.\n",
      "Layer model.13.cv3.conv.weight is frozen.\n",
      "Layer model.13.cv3.bn.weight is frozen.\n",
      "Layer model.13.cv3.bn.bias is frozen.\n",
      "Layer model.13.m.0.cv1.conv.weight is frozen.\n",
      "Layer model.13.m.0.cv1.bn.weight is frozen.\n",
      "Layer model.13.m.0.cv1.bn.bias is frozen.\n",
      "Layer model.13.m.0.cv2.conv.weight is frozen.\n",
      "Layer model.13.m.0.cv2.bn.weight is frozen.\n",
      "Layer model.13.m.0.cv2.bn.bias is frozen.\n",
      "Layer model.14.conv.weight is frozen.\n",
      "Layer model.14.bn.weight is frozen.\n",
      "Layer model.14.bn.bias is frozen.\n",
      "Layer model.17.cv1.conv.weight is frozen.\n",
      "Layer model.17.cv1.bn.weight is frozen.\n",
      "Layer model.17.cv1.bn.bias is frozen.\n",
      "Layer model.17.cv2.conv.weight is frozen.\n",
      "Layer model.17.cv2.bn.weight is frozen.\n",
      "Layer model.17.cv2.bn.bias is frozen.\n",
      "Layer model.17.cv3.conv.weight is frozen.\n",
      "Layer model.17.cv3.bn.weight is frozen.\n",
      "Layer model.17.cv3.bn.bias is frozen.\n",
      "Layer model.17.m.0.cv1.conv.weight is frozen.\n",
      "Layer model.17.m.0.cv1.bn.weight is frozen.\n",
      "Layer model.17.m.0.cv1.bn.bias is frozen.\n",
      "Layer model.17.m.0.cv2.conv.weight is frozen.\n",
      "Layer model.17.m.0.cv2.bn.weight is frozen.\n",
      "Layer model.17.m.0.cv2.bn.bias is frozen.\n",
      "Layer model.18.conv.weight is frozen.\n",
      "Layer model.18.bn.weight is frozen.\n",
      "Layer model.18.bn.bias is frozen.\n",
      "Layer model.20.cv1.conv.weight is frozen.\n",
      "Layer model.20.cv1.bn.weight is frozen.\n",
      "Layer model.20.cv1.bn.bias is frozen.\n",
      "Layer model.20.cv2.conv.weight is frozen.\n",
      "Layer model.20.cv2.bn.weight is frozen.\n",
      "Layer model.20.cv2.bn.bias is frozen.\n",
      "Layer model.20.cv3.conv.weight is frozen.\n",
      "Layer model.20.cv3.bn.weight is frozen.\n",
      "Layer model.20.cv3.bn.bias is frozen.\n",
      "Layer model.20.m.0.cv1.conv.weight is frozen.\n",
      "Layer model.20.m.0.cv1.bn.weight is frozen.\n",
      "Layer model.20.m.0.cv1.bn.bias is frozen.\n",
      "Layer model.20.m.0.cv2.conv.weight is frozen.\n",
      "Layer model.20.m.0.cv2.bn.weight is frozen.\n",
      "Layer model.20.m.0.cv2.bn.bias is frozen.\n",
      "Layer model.21.conv.weight is frozen.\n",
      "Layer model.21.bn.weight is frozen.\n",
      "Layer model.21.bn.bias is frozen.\n",
      "Layer model.23.cv1.conv.weight is frozen.\n",
      "Layer model.23.cv1.bn.weight is frozen.\n",
      "Layer model.23.cv1.bn.bias is frozen.\n",
      "Layer model.23.cv2.conv.weight is frozen.\n",
      "Layer model.23.cv2.bn.weight is frozen.\n",
      "Layer model.23.cv2.bn.bias is frozen.\n",
      "Layer model.23.cv3.conv.weight is frozen.\n",
      "Layer model.23.cv3.bn.weight is frozen.\n",
      "Layer model.23.cv3.bn.bias is frozen.\n",
      "Layer model.23.m.0.cv1.conv.weight is frozen.\n",
      "Layer model.23.m.0.cv1.bn.weight is frozen.\n",
      "Layer model.23.m.0.cv1.bn.bias is frozen.\n",
      "Layer model.23.m.0.cv2.conv.weight is frozen.\n",
      "Layer model.23.m.0.cv2.bn.weight is frozen.\n",
      "Layer model.23.m.0.cv2.bn.bias is frozen.\n",
      "Layer model.24.cv2.0.0.conv.weight is frozen.\n",
      "Layer model.24.cv2.0.0.bn.weight is frozen.\n",
      "Layer model.24.cv2.0.0.bn.bias is frozen.\n",
      "Layer model.24.cv2.0.1.conv.weight is frozen.\n",
      "Layer model.24.cv2.0.1.bn.weight is frozen.\n",
      "Layer model.24.cv2.0.1.bn.bias is frozen.\n",
      "Layer model.24.cv2.0.2.weight is frozen.\n",
      "Layer model.24.cv2.0.2.bias is frozen.\n",
      "Layer model.24.cv2.1.0.conv.weight is frozen.\n",
      "Layer model.24.cv2.1.0.bn.weight is frozen.\n",
      "Layer model.24.cv2.1.0.bn.bias is frozen.\n",
      "Layer model.24.cv2.1.1.conv.weight is frozen.\n",
      "Layer model.24.cv2.1.1.bn.weight is frozen.\n",
      "Layer model.24.cv2.1.1.bn.bias is frozen.\n",
      "Layer model.24.cv2.1.2.weight is frozen.\n",
      "Layer model.24.cv2.1.2.bias is frozen.\n",
      "Layer model.24.cv2.2.0.conv.weight is frozen.\n",
      "Layer model.24.cv2.2.0.bn.weight is frozen.\n",
      "Layer model.24.cv2.2.0.bn.bias is frozen.\n",
      "Layer model.24.cv2.2.1.conv.weight is frozen.\n",
      "Layer model.24.cv2.2.1.bn.weight is frozen.\n",
      "Layer model.24.cv2.2.1.bn.bias is frozen.\n",
      "Layer model.24.cv2.2.2.weight is frozen.\n",
      "Layer model.24.cv2.2.2.bias is frozen.\n",
      "Layer model.24.cv3.0.0.conv.weight is frozen.\n",
      "Layer model.24.cv3.0.0.bn.weight is frozen.\n",
      "Layer model.24.cv3.0.0.bn.bias is frozen.\n",
      "Layer model.24.cv3.0.1.conv.weight is frozen.\n",
      "Layer model.24.cv3.0.1.bn.weight is frozen.\n",
      "Layer model.24.cv3.0.1.bn.bias is frozen.\n",
      "Layer model.24.cv3.0.2.weight is frozen.\n",
      "Layer model.24.cv3.0.2.bias is frozen.\n",
      "Layer model.24.cv3.1.0.conv.weight is frozen.\n",
      "Layer model.24.cv3.1.0.bn.weight is frozen.\n",
      "Layer model.24.cv3.1.0.bn.bias is frozen.\n",
      "Layer model.24.cv3.1.1.conv.weight is frozen.\n",
      "Layer model.24.cv3.1.1.bn.weight is frozen.\n",
      "Layer model.24.cv3.1.1.bn.bias is frozen.\n",
      "Layer model.24.cv3.1.2.weight is frozen.\n",
      "Layer model.24.cv3.1.2.bias is frozen.\n",
      "Layer model.24.cv3.2.0.conv.weight is frozen.\n",
      "Layer model.24.cv3.2.0.bn.weight is frozen.\n",
      "Layer model.24.cv3.2.0.bn.bias is frozen.\n",
      "Layer model.24.cv3.2.1.conv.weight is frozen.\n",
      "Layer model.24.cv3.2.1.bn.weight is frozen.\n",
      "Layer model.24.cv3.2.1.bn.bias is frozen.\n",
      "Layer model.24.cv3.2.2.weight is frozen.\n",
      "Layer model.24.cv3.2.2.bias is frozen.\n",
      "Layer model.24.dfl.conv.weight is frozen.\n",
      "Layer model.24.cv2.0.0.conv.weight is unfrozen.\n",
      "Layer model.24.cv2.0.0.bn.weight is unfrozen.\n",
      "Layer model.24.cv2.0.0.bn.bias is unfrozen.\n",
      "Layer model.24.cv2.0.1.conv.weight is unfrozen.\n",
      "Layer model.24.cv2.0.1.bn.weight is unfrozen.\n",
      "Layer model.24.cv2.0.1.bn.bias is unfrozen.\n",
      "New https://pypi.org/project/ultralytics/8.2.14 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.10  Python-3.11.5 torch-2.3.0+cpu CPU (11th Gen Intel Core(TM) i5-11320H 3.20GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov5su.pt, data=datav5.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train32, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train32\n",
      "Overriding model.yaml nc=80 with nc=8\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \n",
      " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \n",
      " 24        [17, 20, 23]  1   2119144  ultralytics.nn.modules.head.Detect           [8, [128, 256, 512]]          \n",
      "YOLOv5s summary: 262 layers, 9125288 parameters, 9125272 gradients, 24.1 GFLOPs\n",
      "\n",
      "Transferred 421/427 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train32', view at http://localhost:6006/\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Mahmoud\\Downloads\\yolov5\\KITTI-3\\train\\labels.cache... 5223 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5223/5223 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Mahmoud\\Downloads\\yolov5\\KITTI-3\\valid\\labels.cache... 1495 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1495/1495 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train32\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000833, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train32\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10         0G      1.317      1.581      1.217         31        640: 100%|██████████| 327/327 [1:45:49<00:00, 19.42s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [09:44<00:00, 12.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1495       8018      0.497      0.447      0.452       0.27\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10         0G      1.203      1.032      1.169         41        640: 100%|██████████| 327/327 [1:44:19<00:00, 19.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [10:02<00:00, 12.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1495       8018      0.574       0.44      0.486      0.284\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10         0G       1.17     0.9612      1.156         42        640: 100%|██████████| 327/327 [6:17:00<00:00, 69.17s/it]     \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [09:40<00:00, 12.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1495       8018      0.599      0.481      0.534      0.323\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10         0G       1.12     0.8846      1.133         29        640: 100%|██████████| 327/327 [1:44:13<00:00, 19.12s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [11:34<00:00, 14.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1495       8018      0.635      0.547      0.607      0.362\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10         0G      1.073     0.8156      1.108         27        640: 100%|██████████| 327/327 [2:00:15<00:00, 22.07s/it]  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [09:45<00:00, 12.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1495       8018      0.709      0.565      0.633      0.389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10         0G      1.031     0.7518      1.081         55        640: 100%|██████████| 327/327 [1:59:12<00:00, 21.87s/it]  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [09:06<00:00, 11.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1495       8018      0.716      0.661      0.721      0.462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10         0G     0.9811     0.6989      1.062         23        640: 100%|██████████| 327/327 [2:16:31<00:00, 25.05s/it]  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [09:34<00:00, 12.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1495       8018      0.693       0.65      0.713      0.475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10         0G     0.9453     0.6467      1.046         29        640: 100%|██████████| 327/327 [1:42:18<00:00, 18.77s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [09:34<00:00, 12.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1495       8018      0.771      0.717      0.782      0.526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10         0G     0.9017     0.6101      1.024         29        640: 100%|██████████| 327/327 [1:43:34<00:00, 19.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [09:36<00:00, 12.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1495       8018      0.847      0.712      0.808      0.554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10         0G     0.8664     0.5736      1.006         29        640: 100%|██████████| 327/327 [3:41:01<00:00, 40.56s/it]     \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [10:07<00:00, 12.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1495       8018      0.838      0.749      0.826      0.576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 26.562 hours.\n",
      "Optimizer stripped from runs\\detect\\train32\\weights\\last.pt, 18.5MB\n",
      "Optimizer stripped from runs\\detect\\train32\\weights\\best.pt, 18.5MB\n",
      "\n",
      "Validating runs\\detect\\train32\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.10  Python-3.11.5 torch-2.3.0+cpu CPU (11th Gen Intel Core(TM) i5-11320H 3.20GHz)\n",
      "YOLOv5s summary (fused): 193 layers, 9114632 parameters, 0 gradients, 23.8 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [08:23<00:00, 10.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1495       8018      0.838      0.748      0.826      0.576\n",
      "                   Car       1495       5627      0.883      0.932      0.962      0.777\n",
      "               Cyclist       1495        330      0.872      0.682      0.785      0.486\n",
      "                  Misc       1495        196      0.924      0.663      0.804      0.553\n",
      "            Pedestrian       1495        905       0.79      0.645      0.753       0.39\n",
      "        Person_sitting       1495         52      0.725      0.365      0.507       0.29\n",
      "                  Tram       1495        113      0.724      0.894      0.904      0.619\n",
      "                 Truck       1495        230      0.927      0.937      0.968      0.788\n",
      "                   Van       1495        565      0.861      0.869      0.922      0.704\n",
      "Speed: 4.8ms preprocess, 322.3ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train32\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO('yolov5su.pt')\n",
    "\n",
    "\n",
    "for name, param in model.model.named_parameters():\n",
    "    param.requires_grad = False\n",
    "    print(f'Layer {name} is frozen.')\n",
    "\n",
    "\n",
    "layers_to_finetune = [\n",
    "    'model.24.cv2.0.0.conv.weight', 'model.24.cv2.0.0.bn.weight', 'model.24.cv2.0.0.bn.bias',\n",
    "    'model.24.cv2.0.1.conv.weight', 'model.24.cv2.0.1.bn.weight', 'model.24.cv2.0.1.bn.bias',\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "for name, param in model.model.named_parameters():\n",
    "    if name in layers_to_finetune:\n",
    "        param.requires_grad = True\n",
    "        print(f'Layer {name} is unfrozen.')\n",
    "\n",
    "\n",
    "results = model.train(data='datav5.yaml', epochs=10, batch=16, imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Mahmoud\\Downloads\\kitti-object-detection-DatasetNinja\\test\\img\\004594.png: 224x640 1 Car, 2 Miscs, 201.3ms\n",
      "Speed: 9.9ms preprocess, 201.3ms inference, 17.1ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model=YOLO(r'C:\\Users\\Mahmoud\\Downloads\\yolov5\\runs\\detect\\data train\\train2.1\\weights\\last.pt')\n",
    "model=YOLO(r'C:\\Users\\Mahmoud\\Downloads\\yolov5\\runs\\detect\\data train\\train2.1\\weights\\best.pt')\n",
    "results=model(r'C:\\Users\\Mahmoud\\Downloads\\kitti-object-detection-DatasetNinja\\test\\img\\004594.png',save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer model.0.conv.weight is frozen.\n",
      "Layer model.0.bn.weight is frozen.\n",
      "Layer model.0.bn.bias is frozen.\n",
      "Layer model.1.conv.weight is frozen.\n",
      "Layer model.1.bn.weight is frozen.\n",
      "Layer model.1.bn.bias is frozen.\n",
      "Layer model.2.cv1.conv.weight is frozen.\n",
      "Layer model.2.cv1.bn.weight is frozen.\n",
      "Layer model.2.cv1.bn.bias is frozen.\n",
      "Layer model.2.cv2.conv.weight is frozen.\n",
      "Layer model.2.cv2.bn.weight is frozen.\n",
      "Layer model.2.cv2.bn.bias is frozen.\n",
      "Layer model.2.cv3.conv.weight is frozen.\n",
      "Layer model.2.cv3.bn.weight is frozen.\n",
      "Layer model.2.cv3.bn.bias is frozen.\n",
      "Layer model.2.m.0.cv1.conv.weight is frozen.\n",
      "Layer model.2.m.0.cv1.bn.weight is frozen.\n",
      "Layer model.2.m.0.cv1.bn.bias is frozen.\n",
      "Layer model.2.m.0.cv2.conv.weight is frozen.\n",
      "Layer model.2.m.0.cv2.bn.weight is frozen.\n",
      "Layer model.2.m.0.cv2.bn.bias is frozen.\n",
      "Layer model.3.conv.weight is frozen.\n",
      "Layer model.3.bn.weight is frozen.\n",
      "Layer model.3.bn.bias is frozen.\n",
      "Layer model.4.cv1.conv.weight is frozen.\n",
      "Layer model.4.cv1.bn.weight is frozen.\n",
      "Layer model.4.cv1.bn.bias is frozen.\n",
      "Layer model.4.cv2.conv.weight is frozen.\n",
      "Layer model.4.cv2.bn.weight is frozen.\n",
      "Layer model.4.cv2.bn.bias is frozen.\n",
      "Layer model.4.cv3.conv.weight is frozen.\n",
      "Layer model.4.cv3.bn.weight is frozen.\n",
      "Layer model.4.cv3.bn.bias is frozen.\n",
      "Layer model.4.m.0.cv1.conv.weight is frozen.\n",
      "Layer model.4.m.0.cv1.bn.weight is frozen.\n",
      "Layer model.4.m.0.cv1.bn.bias is frozen.\n",
      "Layer model.4.m.0.cv2.conv.weight is frozen.\n",
      "Layer model.4.m.0.cv2.bn.weight is frozen.\n",
      "Layer model.4.m.0.cv2.bn.bias is frozen.\n",
      "Layer model.4.m.1.cv1.conv.weight is frozen.\n",
      "Layer model.4.m.1.cv1.bn.weight is frozen.\n",
      "Layer model.4.m.1.cv1.bn.bias is frozen.\n",
      "Layer model.4.m.1.cv2.conv.weight is frozen.\n",
      "Layer model.4.m.1.cv2.bn.weight is frozen.\n",
      "Layer model.4.m.1.cv2.bn.bias is frozen.\n",
      "Layer model.5.conv.weight is frozen.\n",
      "Layer model.5.bn.weight is frozen.\n",
      "Layer model.5.bn.bias is frozen.\n",
      "Layer model.6.cv1.conv.weight is frozen.\n",
      "Layer model.6.cv1.bn.weight is frozen.\n",
      "Layer model.6.cv1.bn.bias is frozen.\n",
      "Layer model.6.cv2.conv.weight is frozen.\n",
      "Layer model.6.cv2.bn.weight is frozen.\n",
      "Layer model.6.cv2.bn.bias is frozen.\n",
      "Layer model.6.cv3.conv.weight is frozen.\n",
      "Layer model.6.cv3.bn.weight is frozen.\n",
      "Layer model.6.cv3.bn.bias is frozen.\n",
      "Layer model.6.m.0.cv1.conv.weight is frozen.\n",
      "Layer model.6.m.0.cv1.bn.weight is frozen.\n",
      "Layer model.6.m.0.cv1.bn.bias is frozen.\n",
      "Layer model.6.m.0.cv2.conv.weight is frozen.\n",
      "Layer model.6.m.0.cv2.bn.weight is frozen.\n",
      "Layer model.6.m.0.cv2.bn.bias is frozen.\n",
      "Layer model.6.m.1.cv1.conv.weight is frozen.\n",
      "Layer model.6.m.1.cv1.bn.weight is frozen.\n",
      "Layer model.6.m.1.cv1.bn.bias is frozen.\n",
      "Layer model.6.m.1.cv2.conv.weight is frozen.\n",
      "Layer model.6.m.1.cv2.bn.weight is frozen.\n",
      "Layer model.6.m.1.cv2.bn.bias is frozen.\n",
      "Layer model.6.m.2.cv1.conv.weight is frozen.\n",
      "Layer model.6.m.2.cv1.bn.weight is frozen.\n",
      "Layer model.6.m.2.cv1.bn.bias is frozen.\n",
      "Layer model.6.m.2.cv2.conv.weight is frozen.\n",
      "Layer model.6.m.2.cv2.bn.weight is frozen.\n",
      "Layer model.6.m.2.cv2.bn.bias is frozen.\n",
      "Layer model.7.conv.weight is frozen.\n",
      "Layer model.7.bn.weight is frozen.\n",
      "Layer model.7.bn.bias is frozen.\n",
      "Layer model.8.cv1.conv.weight is frozen.\n",
      "Layer model.8.cv1.bn.weight is frozen.\n",
      "Layer model.8.cv1.bn.bias is frozen.\n",
      "Layer model.8.cv2.conv.weight is frozen.\n",
      "Layer model.8.cv2.bn.weight is frozen.\n",
      "Layer model.8.cv2.bn.bias is frozen.\n",
      "Layer model.8.cv3.conv.weight is frozen.\n",
      "Layer model.8.cv3.bn.weight is frozen.\n",
      "Layer model.8.cv3.bn.bias is frozen.\n",
      "Layer model.8.m.0.cv1.conv.weight is frozen.\n",
      "Layer model.8.m.0.cv1.bn.weight is frozen.\n",
      "Layer model.8.m.0.cv1.bn.bias is frozen.\n",
      "Layer model.8.m.0.cv2.conv.weight is frozen.\n",
      "Layer model.8.m.0.cv2.bn.weight is frozen.\n",
      "Layer model.8.m.0.cv2.bn.bias is frozen.\n",
      "Layer model.9.cv1.conv.weight is frozen.\n",
      "Layer model.9.cv1.bn.weight is frozen.\n",
      "Layer model.9.cv1.bn.bias is frozen.\n",
      "Layer model.9.cv2.conv.weight is frozen.\n",
      "Layer model.9.cv2.bn.weight is frozen.\n",
      "Layer model.9.cv2.bn.bias is frozen.\n",
      "Layer model.10.conv.weight is frozen.\n",
      "Layer model.10.bn.weight is frozen.\n",
      "Layer model.10.bn.bias is frozen.\n",
      "Layer model.13.cv1.conv.weight is frozen.\n",
      "Layer model.13.cv1.bn.weight is frozen.\n",
      "Layer model.13.cv1.bn.bias is frozen.\n",
      "Layer model.13.cv2.conv.weight is frozen.\n",
      "Layer model.13.cv2.bn.weight is frozen.\n",
      "Layer model.13.cv2.bn.bias is frozen.\n",
      "Layer model.13.cv3.conv.weight is frozen.\n",
      "Layer model.13.cv3.bn.weight is frozen.\n",
      "Layer model.13.cv3.bn.bias is frozen.\n",
      "Layer model.13.m.0.cv1.conv.weight is frozen.\n",
      "Layer model.13.m.0.cv1.bn.weight is frozen.\n",
      "Layer model.13.m.0.cv1.bn.bias is frozen.\n",
      "Layer model.13.m.0.cv2.conv.weight is frozen.\n",
      "Layer model.13.m.0.cv2.bn.weight is frozen.\n",
      "Layer model.13.m.0.cv2.bn.bias is frozen.\n",
      "Layer model.14.conv.weight is frozen.\n",
      "Layer model.14.bn.weight is frozen.\n",
      "Layer model.14.bn.bias is frozen.\n",
      "Layer model.17.cv1.conv.weight is frozen.\n",
      "Layer model.17.cv1.bn.weight is frozen.\n",
      "Layer model.17.cv1.bn.bias is frozen.\n",
      "Layer model.17.cv2.conv.weight is frozen.\n",
      "Layer model.17.cv2.bn.weight is frozen.\n",
      "Layer model.17.cv2.bn.bias is frozen.\n",
      "Layer model.17.cv3.conv.weight is frozen.\n",
      "Layer model.17.cv3.bn.weight is frozen.\n",
      "Layer model.17.cv3.bn.bias is frozen.\n",
      "Layer model.17.m.0.cv1.conv.weight is frozen.\n",
      "Layer model.17.m.0.cv1.bn.weight is frozen.\n",
      "Layer model.17.m.0.cv1.bn.bias is frozen.\n",
      "Layer model.17.m.0.cv2.conv.weight is frozen.\n",
      "Layer model.17.m.0.cv2.bn.weight is frozen.\n",
      "Layer model.17.m.0.cv2.bn.bias is frozen.\n",
      "Layer model.18.conv.weight is frozen.\n",
      "Layer model.18.bn.weight is frozen.\n",
      "Layer model.18.bn.bias is frozen.\n",
      "Layer model.20.cv1.conv.weight is frozen.\n",
      "Layer model.20.cv1.bn.weight is frozen.\n",
      "Layer model.20.cv1.bn.bias is frozen.\n",
      "Layer model.20.cv2.conv.weight is frozen.\n",
      "Layer model.20.cv2.bn.weight is frozen.\n",
      "Layer model.20.cv2.bn.bias is frozen.\n",
      "Layer model.20.cv3.conv.weight is frozen.\n",
      "Layer model.20.cv3.bn.weight is frozen.\n",
      "Layer model.20.cv3.bn.bias is frozen.\n",
      "Layer model.20.m.0.cv1.conv.weight is frozen.\n",
      "Layer model.20.m.0.cv1.bn.weight is frozen.\n",
      "Layer model.20.m.0.cv1.bn.bias is frozen.\n",
      "Layer model.20.m.0.cv2.conv.weight is frozen.\n",
      "Layer model.20.m.0.cv2.bn.weight is frozen.\n",
      "Layer model.20.m.0.cv2.bn.bias is frozen.\n",
      "Layer model.21.conv.weight is frozen.\n",
      "Layer model.21.bn.weight is frozen.\n",
      "Layer model.21.bn.bias is frozen.\n",
      "Layer model.23.cv1.conv.weight is frozen.\n",
      "Layer model.23.cv1.bn.weight is frozen.\n",
      "Layer model.23.cv1.bn.bias is frozen.\n",
      "Layer model.23.cv2.conv.weight is frozen.\n",
      "Layer model.23.cv2.bn.weight is frozen.\n",
      "Layer model.23.cv2.bn.bias is frozen.\n",
      "Layer model.23.cv3.conv.weight is frozen.\n",
      "Layer model.23.cv3.bn.weight is frozen.\n",
      "Layer model.23.cv3.bn.bias is frozen.\n",
      "Layer model.23.m.0.cv1.conv.weight is frozen.\n",
      "Layer model.23.m.0.cv1.bn.weight is frozen.\n",
      "Layer model.23.m.0.cv1.bn.bias is frozen.\n",
      "Layer model.23.m.0.cv2.conv.weight is frozen.\n",
      "Layer model.23.m.0.cv2.bn.weight is frozen.\n",
      "Layer model.23.m.0.cv2.bn.bias is frozen.\n",
      "Layer model.24.cv2.0.0.conv.weight is frozen.\n",
      "Layer model.24.cv2.0.0.bn.weight is frozen.\n",
      "Layer model.24.cv2.0.0.bn.bias is frozen.\n",
      "Layer model.24.cv2.0.1.conv.weight is frozen.\n",
      "Layer model.24.cv2.0.1.bn.weight is frozen.\n",
      "Layer model.24.cv2.0.1.bn.bias is frozen.\n",
      "Layer model.24.cv2.0.2.weight is frozen.\n",
      "Layer model.24.cv2.0.2.bias is frozen.\n",
      "Layer model.24.cv2.1.0.conv.weight is frozen.\n",
      "Layer model.24.cv2.1.0.bn.weight is frozen.\n",
      "Layer model.24.cv2.1.0.bn.bias is frozen.\n",
      "Layer model.24.cv2.1.1.conv.weight is frozen.\n",
      "Layer model.24.cv2.1.1.bn.weight is frozen.\n",
      "Layer model.24.cv2.1.1.bn.bias is frozen.\n",
      "Layer model.24.cv2.1.2.weight is frozen.\n",
      "Layer model.24.cv2.1.2.bias is frozen.\n",
      "Layer model.24.cv2.2.0.conv.weight is frozen.\n",
      "Layer model.24.cv2.2.0.bn.weight is frozen.\n",
      "Layer model.24.cv2.2.0.bn.bias is frozen.\n",
      "Layer model.24.cv2.2.1.conv.weight is frozen.\n",
      "Layer model.24.cv2.2.1.bn.weight is frozen.\n",
      "Layer model.24.cv2.2.1.bn.bias is frozen.\n",
      "Layer model.24.cv2.2.2.weight is frozen.\n",
      "Layer model.24.cv2.2.2.bias is frozen.\n",
      "Layer model.24.cv3.0.0.conv.weight is frozen.\n",
      "Layer model.24.cv3.0.0.bn.weight is frozen.\n",
      "Layer model.24.cv3.0.0.bn.bias is frozen.\n",
      "Layer model.24.cv3.0.1.conv.weight is frozen.\n",
      "Layer model.24.cv3.0.1.bn.weight is frozen.\n",
      "Layer model.24.cv3.0.1.bn.bias is frozen.\n",
      "Layer model.24.cv3.0.2.weight is frozen.\n",
      "Layer model.24.cv3.0.2.bias is frozen.\n",
      "Layer model.24.cv3.1.0.conv.weight is frozen.\n",
      "Layer model.24.cv3.1.0.bn.weight is frozen.\n",
      "Layer model.24.cv3.1.0.bn.bias is frozen.\n",
      "Layer model.24.cv3.1.1.conv.weight is frozen.\n",
      "Layer model.24.cv3.1.1.bn.weight is frozen.\n",
      "Layer model.24.cv3.1.1.bn.bias is frozen.\n",
      "Layer model.24.cv3.1.2.weight is frozen.\n",
      "Layer model.24.cv3.1.2.bias is frozen.\n",
      "Layer model.24.cv3.2.0.conv.weight is frozen.\n",
      "Layer model.24.cv3.2.0.bn.weight is frozen.\n",
      "Layer model.24.cv3.2.0.bn.bias is frozen.\n",
      "Layer model.24.cv3.2.1.conv.weight is frozen.\n",
      "Layer model.24.cv3.2.1.bn.weight is frozen.\n",
      "Layer model.24.cv3.2.1.bn.bias is frozen.\n",
      "Layer model.24.cv3.2.2.weight is frozen.\n",
      "Layer model.24.cv3.2.2.bias is frozen.\n",
      "Layer model.24.dfl.conv.weight is frozen.\n",
      "Layer new_conv1.weight is frozen.\n",
      "Layer new_conv1.bias is frozen.\n",
      "Layer new_bn1.weight is frozen.\n",
      "Layer new_bn1.bias is frozen.\n",
      "Layer new_conv2.weight is frozen.\n",
      "Layer new_conv2.bias is frozen.\n",
      "Layer model.new_conv1 is unfrozen and added.\n",
      "Layer model.new_bn1 is unfrozen and added.\n",
      "Layer model.new_conv2 is unfrozen and added.\n",
      "Layer model.new_relu is unfrozen and added.\n",
      "CustomYOLO(\n",
      "  (model): DetectionModel(\n",
      "    (model): Sequential(\n",
      "      (0): Conv(\n",
      "        (conv): Conv2d(3, 32, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv(\n",
      "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (2): C3(\n",
      "        (cv1): Conv(\n",
      "          (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv2): Conv(\n",
      "          (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv3): Conv(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (m): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (cv1): Conv(\n",
      "              (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (cv2): Conv(\n",
      "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): Conv(\n",
      "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (4): C3(\n",
      "        (cv1): Conv(\n",
      "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv2): Conv(\n",
      "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv3): Conv(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (m): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (cv1): Conv(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (cv2): Conv(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Bottleneck(\n",
      "            (cv1): Conv(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (cv2): Conv(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (5): Conv(\n",
      "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (6): C3(\n",
      "        (cv1): Conv(\n",
      "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv2): Conv(\n",
      "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv3): Conv(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (m): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (cv1): Conv(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (cv2): Conv(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Bottleneck(\n",
      "            (cv1): Conv(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (cv2): Conv(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (2): Bottleneck(\n",
      "            (cv1): Conv(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (cv2): Conv(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (7): Conv(\n",
      "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (8): C3(\n",
      "        (cv1): Conv(\n",
      "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv2): Conv(\n",
      "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv3): Conv(\n",
      "          (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (m): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (cv1): Conv(\n",
      "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (cv2): Conv(\n",
      "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (9): SPPF(\n",
      "        (cv1): Conv(\n",
      "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv2): Conv(\n",
      "          (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (10): Conv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (11): Upsample(scale_factor=2.0, mode='nearest')\n",
      "      (12): Concat()\n",
      "      (13): C3(\n",
      "        (cv1): Conv(\n",
      "          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv2): Conv(\n",
      "          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv3): Conv(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (m): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (cv1): Conv(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (cv2): Conv(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (14): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (15): Upsample(scale_factor=2.0, mode='nearest')\n",
      "      (16): Concat()\n",
      "      (17): C3(\n",
      "        (cv1): Conv(\n",
      "          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv2): Conv(\n",
      "          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv3): Conv(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (m): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (cv1): Conv(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (cv2): Conv(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (18): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (19): Concat()\n",
      "      (20): C3(\n",
      "        (cv1): Conv(\n",
      "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv2): Conv(\n",
      "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv3): Conv(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (m): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (cv1): Conv(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (cv2): Conv(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (21): Conv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (22): Concat()\n",
      "      (23): C3(\n",
      "        (cv1): Conv(\n",
      "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv2): Conv(\n",
      "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv3): Conv(\n",
      "          (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (m): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (cv1): Conv(\n",
      "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (cv2): Conv(\n",
      "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (24): Detect(\n",
      "        (cv2): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Conv(\n",
      "              (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Conv(\n",
      "              (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (2): Sequential(\n",
      "            (0): Conv(\n",
      "              (conv): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (cv3): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Conv(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): Conv2d(128, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Conv(\n",
      "              (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): Conv2d(128, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (2): Sequential(\n",
      "            (0): Conv(\n",
      "              (conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): Conv2d(128, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (dfl): DFL(\n",
      "          (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (new_conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (new_bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (new_conv2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (new_relu): ReLU()\n",
      "  )\n",
      "  (new_conv_layer1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (new_bn_layer1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (new_conv_layer2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (new_relu_layer): ReLU()\n",
      ")\n",
      "New https://pypi.org/project/ultralytics/8.2.16 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.10  Python-3.11.5 torch-2.3.0+cpu CPU (11th Gen Intel Core(TM) i5-11320H 3.20GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov5su.pt, data=datav5.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train\n",
      "Overriding model.yaml nc=80 with nc=8\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \n",
      " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \n",
      " 24        [17, 20, 23]  1   2119144  ultralytics.nn.modules.head.Detect           [8, [128, 256, 512]]          \n",
      "YOLOv5s summary: 262 layers, 9125288 parameters, 9125272 gradients, 24.1 GFLOPs\n",
      "\n",
      "Transferred 421/427 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train', view at http://localhost:6006/\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Mahmoud\\Downloads\\yolov5\\KITTI-3\\train\\labels... 4223 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4223/4223 [00:09<00:00, 433.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\Mahmoud\\Downloads\\yolov5\\KITTI-3\\train\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Mahmoud\\Downloads\\yolov5\\KITTI-3\\valid\\labels.cache... 1495 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1495/1495 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000833, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10         0G      1.343      1.661      1.224         99        640: 100%|██████████| 264/264 [1:39:45<00:00, 22.67s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [09:56<00:00, 12.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1495       8018      0.482      0.411      0.407      0.231\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10         0G      1.219      1.074      1.171         88        640: 100%|██████████| 264/264 [2:36:38<00:00, 35.60s/it]   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [10:11<00:00, 13.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1495       8018      0.554      0.434      0.451      0.257\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10         0G      1.182     0.9882       1.16         82        640: 100%|██████████| 264/264 [1:32:30<00:00, 21.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [11:21<00:00, 14.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1495       8018      0.531      0.498      0.521      0.311\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10         0G      1.143     0.9231      1.145         93        640: 100%|██████████| 264/264 [1:32:15<00:00, 20.97s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [09:57<00:00, 12.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1495       8018      0.718      0.522      0.548      0.339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10         0G      1.093     0.8406      1.118         77        640: 100%|██████████| 264/264 [1:29:52<00:00, 20.43s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [09:57<00:00, 12.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1495       8018      0.659      0.595      0.639      0.404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10         0G      1.045     0.7759       1.09         60        640: 100%|██████████| 264/264 [1:30:57<00:00, 20.67s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [09:57<00:00, 12.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1495       8018      0.739      0.636      0.695      0.445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10         0G      1.004     0.7277      1.068         72        640: 100%|██████████| 264/264 [1:32:50<00:00, 21.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [11:21<00:00, 14.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1495       8018      0.746      0.675      0.732      0.475\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10         0G     0.9595     0.6727      1.046         95        640: 100%|██████████| 264/264 [1:39:52<00:00, 22.70s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [09:54<00:00, 12.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1495       8018      0.777      0.658      0.749      0.492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10         0G     0.9244      0.631      1.031         92        640: 100%|██████████| 264/264 [1:28:25<00:00, 20.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [09:55<00:00, 12.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1495       8018      0.789      0.735      0.788      0.533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10         0G      0.888     0.5953      1.015         82        640: 100%|██████████| 264/264 [1:28:24<00:00, 20.09s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [09:55<00:00, 12.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1495       8018      0.778      0.754      0.802       0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 18.245 hours.\n",
      "Optimizer stripped from runs\\detect\\train\\weights\\last.pt, 18.5MB\n",
      "Optimizer stripped from runs\\detect\\train\\weights\\best.pt, 18.5MB\n",
      "\n",
      "Validating runs\\detect\\train\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.10  Python-3.11.5 torch-2.3.0+cpu CPU (11th Gen Intel Core(TM) i5-11320H 3.20GHz)\n",
      "YOLOv5s summary (fused): 193 layers, 9114632 parameters, 0 gradients, 23.8 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [07:49<00:00,  9.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1495       8018      0.777      0.754      0.802      0.551\n",
      "                   Car       1495       5627      0.867      0.933      0.958      0.765\n",
      "               Cyclist       1495        330      0.738      0.709      0.741      0.446\n",
      "                  Misc       1495        196      0.804      0.684      0.755      0.512\n",
      "            Pedestrian       1495        905       0.75       0.66      0.746      0.385\n",
      "        Person_sitting       1495         52      0.669      0.388      0.503      0.262\n",
      "                  Tram       1495        113      0.636      0.883      0.849      0.591\n",
      "                 Truck       1495        230      0.917      0.909      0.957      0.767\n",
      "                   Van       1495        565      0.836      0.867      0.906      0.676\n",
      "Speed: 4.3ms preprocess, 300.0ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CustomYOLO(YOLO):\n",
    "    def __init__(self, model_name):\n",
    "        super().__init__(model_name)  \n",
    "        \n",
    "        \n",
    "        self.new_conv_layer1 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.new_bn_layer1 = nn.BatchNorm2d(512)\n",
    "        self.new_conv_layer2 = nn.Conv2d(in_channels=512, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.new_relu_layer = nn.ReLU()\n",
    "        \n",
    "        \n",
    "        self.model.add_module('new_conv1', self.new_conv_layer1)\n",
    "        self.model.add_module('new_bn1', self.new_bn_layer1)\n",
    "        self.model.add_module('new_conv2', self.new_conv_layer2)\n",
    "        self.model.add_module('new_relu', self.new_relu_layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.model(x)\n",
    "        \n",
    "        x = self.new_conv_layer1(x)\n",
    "        x = self.new_bn_layer1(x)\n",
    "        x = self.new_conv_layer2(x)\n",
    "        x = self.new_relu_layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = CustomYOLO('yolov5su.pt')\n",
    "\n",
    "\n",
    "for name, param in model.model.named_parameters():\n",
    "    param.requires_grad = False\n",
    "    print(f'Layer {name} is frozen.')\n",
    "\n",
    "\n",
    "new_layers = ['new_conv1', 'new_bn1', 'new_conv2', 'new_relu']\n",
    "for name, module in model.named_modules():\n",
    "    if any(new_layer in name for new_layer in new_layers):\n",
    "        for param in module.parameters():\n",
    "            param.requires_grad = True\n",
    "        print(f'Layer {name} is unfrozen and added.')\n",
    "\n",
    "\n",
    "print(model)\n",
    "results=model.train(data='datav5.yaml', epochs=10, batch=16, imgsz=640)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Mahmoud\\Downloads\\yolov5\\KITTI-3\\test\\images\\005767_png.rf.9a3114ffdaeb2b0bc6954b389c32c05c.jpg: 640x640 3 Cars, 412.9ms\n",
      "Speed: 6.8ms preprocess, 412.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model=YOLO(r'C:\\Users\\Mahmoud\\Downloads\\yolov5\\runs\\detect\\train\\weights\\last.pt')\n",
    "model=YOLO(r'C:\\Users\\Mahmoud\\Downloads\\yolov5\\runs\\detect\\train\\weights\\best.pt')\n",
    "results=model(r'C:\\Users\\Mahmoud\\Downloads\\yolov5\\KITTI-3\\test\\images\\005767_png.rf.9a3114ffdaeb2b0bc6954b389c32c05c.jpg',save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomYOLO(\n",
      "  (model): DetectionModel(\n",
      "    (model): Sequential(\n",
      "      (0): Conv(\n",
      "        (conv): Conv2d(3, 32, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv(\n",
      "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (2): C3(\n",
      "        (cv1): Conv(\n",
      "          (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv2): Conv(\n",
      "          (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv3): Conv(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (m): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (cv1): Conv(\n",
      "              (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (cv2): Conv(\n",
      "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): Conv(\n",
      "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (4): C3(\n",
      "        (cv1): Conv(\n",
      "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv2): Conv(\n",
      "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv3): Conv(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (m): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (cv1): Conv(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (cv2): Conv(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Bottleneck(\n",
      "            (cv1): Conv(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (cv2): Conv(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (5): Conv(\n",
      "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (6): C3(\n",
      "        (cv1): Conv(\n",
      "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv2): Conv(\n",
      "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv3): Conv(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (m): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (cv1): Conv(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (cv2): Conv(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Bottleneck(\n",
      "            (cv1): Conv(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (cv2): Conv(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (2): Bottleneck(\n",
      "            (cv1): Conv(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (cv2): Conv(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (7): Conv(\n",
      "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (8): C3(\n",
      "        (cv1): Conv(\n",
      "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv2): Conv(\n",
      "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv3): Conv(\n",
      "          (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (m): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (cv1): Conv(\n",
      "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (cv2): Conv(\n",
      "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (9): SPPF(\n",
      "        (cv1): Conv(\n",
      "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv2): Conv(\n",
      "          (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (10): Conv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (11): Upsample(scale_factor=2.0, mode='nearest')\n",
      "      (12): Concat()\n",
      "      (13): C3(\n",
      "        (cv1): Conv(\n",
      "          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv2): Conv(\n",
      "          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv3): Conv(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (m): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (cv1): Conv(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (cv2): Conv(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (14): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (15): Upsample(scale_factor=2.0, mode='nearest')\n",
      "      (16): Concat()\n",
      "      (17): C3(\n",
      "        (cv1): Conv(\n",
      "          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv2): Conv(\n",
      "          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv3): Conv(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (m): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (cv1): Conv(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (cv2): Conv(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (18): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (19): Concat()\n",
      "      (20): C3(\n",
      "        (cv1): Conv(\n",
      "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv2): Conv(\n",
      "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv3): Conv(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (m): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (cv1): Conv(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (cv2): Conv(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (21): Conv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (22): Concat()\n",
      "      (23): C3(\n",
      "        (cv1): Conv(\n",
      "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv2): Conv(\n",
      "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv3): Conv(\n",
      "          (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (m): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (cv1): Conv(\n",
      "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (cv2): Conv(\n",
      "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (24): Detect(\n",
      "        (cv2): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Conv(\n",
      "              (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Conv(\n",
      "              (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (2): Sequential(\n",
      "            (0): Conv(\n",
      "              (conv): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (cv3): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Conv(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): Conv2d(128, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Conv(\n",
      "              (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): Conv2d(128, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (2): Sequential(\n",
      "            (0): Conv(\n",
      "              (conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): Conv2d(128, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (dfl): DFL(\n",
      "          (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (new_conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (new_bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (new_conv2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (new_relu): ReLU()\n",
      "  )\n",
      "  (new_conv_layer1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (new_bn_layer1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (new_conv_layer2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (new_relu_layer): ReLU()\n",
      ")\n",
      "Layer new_conv1 is present in the model.\n",
      "Layer new_bn1 is present in the model.\n",
      "Layer new_conv2 is present in the model.\n",
      "Layer new_relu is present in the model.\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.10  Python-3.11.5 torch-2.3.0+cpu CPU (11th Gen Intel Core(TM) i5-11320H 3.20GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov5su.pt, data=datav5.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train7, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train7\n",
      "Overriding model.yaml nc=80 with nc=8\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \n",
      " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \n",
      " 24        [17, 20, 23]  1   2119144  ultralytics.nn.modules.head.Detect           [8, [128, 256, 512]]          \n",
      "YOLOv5s summary: 262 layers, 9125288 parameters, 9125272 gradients, 24.1 GFLOPs\n",
      "\n",
      "Transferred 421/427 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train7', view at http://localhost:6006/\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Mahmoud\\Downloads\\yolov5\\KITTI-3\\train\\labels.cache... 5223 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5223/5223 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Mahmoud\\Downloads\\yolov5\\KITTI-3\\valid\\labels.cache... 1495 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1495/1495 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train7\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000833, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train7\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10         0G      1.317      1.581      1.217         31        640: 100%|██████████| 327/327 [1:48:22<00:00, 19.89s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [10:04<00:00, 12.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1495       8018      0.497      0.447      0.452       0.27\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10         0G      1.203      1.032      1.169         41        640: 100%|██████████| 327/327 [1:54:07<00:00, 20.94s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [11:45<00:00, 15.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1495       8018      0.574       0.44      0.486      0.284\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10         0G       1.17     0.9612      1.156         42        640: 100%|██████████| 327/327 [2:06:35<00:00, 23.23s/it]  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [09:59<00:00, 12.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1495       8018      0.599      0.481      0.534      0.323\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10         0G       1.12     0.8846      1.133         29        640: 100%|██████████| 327/327 [1:46:13<00:00, 19.49s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [10:07<00:00, 12.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1495       8018      0.635      0.547      0.607      0.362\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10         0G      1.073     0.8156      1.108         27        640: 100%|██████████| 327/327 [1:47:33<00:00, 19.73s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [10:06<00:00, 12.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1495       8018      0.709      0.565      0.633      0.389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10         0G      1.031     0.7518      1.081         55        640: 100%|██████████| 327/327 [3:36:29<00:00, 39.72s/it]     \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [10:10<00:00, 12.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1495       8018      0.716      0.661      0.721      0.462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10         0G     0.9811     0.6989      1.062         23        640: 100%|██████████| 327/327 [1:52:55<00:00, 20.72s/it]  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [10:09<00:00, 12.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1495       8018      0.693       0.65      0.713      0.475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10         0G     0.9453     0.6467      1.046         29        640: 100%|██████████| 327/327 [1:58:53<00:00, 21.81s/it]  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [10:24<00:00, 13.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1495       8018      0.771      0.717      0.782      0.526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10         0G     0.9017     0.6101      1.024         29        640: 100%|██████████| 327/327 [1:47:32<00:00, 19.73s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [10:21<00:00, 13.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1495       8018      0.847      0.712      0.808      0.554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10         0G     0.8707     0.5807      1.006        108        640:  36%|███▋      | 119/327 [39:19<1:09:43, 20.11s/it]"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CustomYOLO(YOLO):\n",
    "    def __init__(self, model_name):\n",
    "        super().__init__(model_name)  \n",
    "        \n",
    "        self.new_conv_layer1 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.new_bn_layer1 = nn.BatchNorm2d(512)\n",
    "        self.new_conv_layer2 = nn.Conv2d(in_channels=512, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.new_relu_layer = nn.ReLU()\n",
    "        \n",
    "        self.model.add_module('new_conv1', self.new_conv_layer1)\n",
    "        self.model.add_module('new_bn1', self.new_bn_layer1)\n",
    "        self.model.add_module('new_conv2', self.new_conv_layer2)\n",
    "        self.model.add_module('new_relu', self.new_relu_layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.model(x)\n",
    "        \n",
    "        x = self.new_conv_layer1(x)\n",
    "        x = self.new_bn_layer1(x)\n",
    "        x = self.new_conv_layer2(x)\n",
    "        x = self.new_relu_layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = CustomYOLO('yolov5su.pt')\n",
    "\n",
    "\n",
    "print(model)\n",
    "\n",
    "\n",
    "def check_layer(model, layer_name):\n",
    "    for name, module in model.named_modules():\n",
    "        if layer_name in name:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "layer_names = ['new_conv1', 'new_bn1', 'new_conv2', 'new_relu']\n",
    "for name in layer_names:\n",
    "    if check_layer(model, name):\n",
    "        print(f\"Layer {name} is in the model.\")\n",
    "    else:\n",
    "        print(f\"Layer {name} is NOT  in the model.\")\n",
    "\n",
    "\n",
    "\n",
    "results = model.train(data='datav5.yaml', epochs=10, batch=16, imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Mahmoud\\Downloads\\yolov5\\KITTI-3\\test\\images\\007436_png.rf.5538f3400bf94153a6b287e6ed13c69a.jpg: 640x640 1 Pedestrian, 288.6ms\n",
      "Speed: 4.0ms preprocess, 288.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model=YOLO(r'C:\\Users\\Mahmoud\\Downloads\\yolov5\\runs\\detect\\data train\\train2.3\\weights\\last.pt')\n",
    "model=YOLO(r'C:\\Users\\Mahmoud\\Downloads\\yolov5\\runs\\detect\\data train\\train2.3\\weights\\best.pt')\n",
    "results=model(r'C:\\Users\\Mahmoud\\Downloads\\yolov5\\KITTI-3\\test\\images\\007436_png.rf.5538f3400bf94153a6b287e6ed13c69a.jpg',save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Total Loss : 0.20\n",
      "Epoch 2, Total Loss : 0.15\n",
      "Epoch 3, Total Loss : 0.14\n",
      "Epoch 4, Total Loss : 0.14\n",
      "Epoch 5, Total Loss : 0.14\n",
      "Epoch 6, Total Loss : 0.14\n",
      "Epoch 7, Total Loss : 0.13\n",
      "Epoch 8, Total Loss : 0.13\n",
      "Epoch 9, Total Loss : 0.13\n",
      "Epoch 10, Total Loss : 0.13\n",
      "Epoch 11, Total Loss : 0.13\n",
      "Epoch 12, Total Loss : 0.13\n",
      "Epoch 13, Total Loss : 0.13\n",
      "Epoch 14, Total Loss : 0.12\n",
      "Epoch 15, Total Loss : 0.12\n",
      "The total accuracy of my model is 86.00%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, ops\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "\n",
    "class KITTIDataset(Dataset):\n",
    "    def __init__(self, img_dir, ann_dir, transform=None, max_objects=50):\n",
    "        self.img_dir = img_dir\n",
    "        self.ann_dir = ann_dir\n",
    "        self.transform = transform\n",
    "        self.images = os.listdir(img_dir)\n",
    "        self.max_objects = max_objects  \n",
    "        self.class_to_idx = {}  \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.images[idx])\n",
    "        ann_path = os.path.join(self.ann_dir, self.images[idx] + '.json')\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        with open(ann_path) as f:\n",
    "            annotations = json.load(f)\n",
    "        \n",
    "        boxes = [obj['points']['exterior'] for obj in annotations['objects']]\n",
    "        labels = [obj['classTitle'] for obj in annotations['objects']]\n",
    "\n",
    "        \n",
    "        for label in labels:\n",
    "            if label not in self.class_to_idx:\n",
    "                self.class_to_idx[label] = len(self.class_to_idx)\n",
    "\n",
    "        \n",
    "        boxes = torch.tensor([[min(box[0][0], box[1][0]), min(box[0][1], box[1][1]),\n",
    "                               max(box[0][0], box[1][0]), max(box[0][1], box[1][1])] for box in boxes], dtype=torch.float32)\n",
    "        \n",
    "        \n",
    "        boxes = ops.box_convert(boxes, in_fmt=\"xyxy\", out_fmt=\"cxcywh\")\n",
    "\n",
    "        \n",
    "        padded_boxes = torch.zeros((self.max_objects, 4))\n",
    "        padded_labels = torch.zeros(self.max_objects, dtype=torch.long)\n",
    "        \n",
    "        if len(boxes) > 0:\n",
    "            padded_boxes[:len(boxes)] = boxes\n",
    "            padded_labels[:len(labels)] = torch.tensor([self.class_to_idx[label] for label in labels], dtype=torch.long)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return {'image': image, 'boxes': padded_boxes, 'labels': padded_labels}\n",
    "\n",
    "class CustomYOLO(nn.Module):\n",
    "    def __init__(self, pretrained_model_path, num_classes=9):\n",
    "        super(CustomYOLO, self).__init__()\n",
    "        self.pretrained_model = YOLO(pretrained_model_path).model  \n",
    "        \n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            self.pretrained_model.model[0],  \n",
    "            self.pretrained_model.model[1],  \n",
    "            self.pretrained_model.model[2], \n",
    "        )\n",
    "        \n",
    "        \n",
    "        num_output_channels = (num_classes + 4) * 50\n",
    "        \n",
    "        \n",
    "        self.custom_layers = nn.Sequential(\n",
    "            nn.Conv2d(64, 256, 3, padding=1),  \n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256, num_output_channels)  \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.custom_layers(x)\n",
    "        return x\n",
    "\n",
    "def calculate_loss(pred_boxes, pred_labels, true_boxes, true_labels, criterion_cls):\n",
    "    \n",
    "    true_labels = true_labels.view(-1)\n",
    "    valid_indices = true_labels != 0  \n",
    "    true_labels = true_labels[valid_indices]\n",
    "    pred_labels = pred_labels.view(-1, pred_labels.size(-1))\n",
    "    pred_labels = pred_labels[valid_indices]\n",
    "\n",
    "    \n",
    "    cls_loss = criterion_cls(pred_labels, true_labels)\n",
    "\n",
    "    \n",
    "    total_loss = cls_loss\n",
    "    return total_loss\n",
    "\n",
    "def main():\n",
    "    \n",
    "    train_img_dir = r'C:\\Users\\Mahmoud\\Downloads\\kitti-object-detection-DatasetNinja\\train\\img'\n",
    "    train_ann_dir = r'C:\\Users\\Mahmoud\\Downloads\\kitti-object-detection-DatasetNinja\\train\\ann'\n",
    "\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((640, 640)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    \n",
    "    dataset = KITTIDataset(train_img_dir, train_ann_dir, transform=transform, max_objects=50)\n",
    "    dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "    \n",
    "    model = CustomYOLO('yolov5su.pt')\n",
    "    model.train()\n",
    "\n",
    "    \n",
    "    criterion_cls = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    max_possible_loss = len(dataset) * 50  \n",
    "\n",
    "    for epoch in range(15):  \n",
    "        total_loss = 0\n",
    "        for batch in dataloader:\n",
    "            images, true_labels = batch['image'], batch['labels']\n",
    "            true_boxes = batch['boxes']\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            \n",
    "            \n",
    "            outputs = outputs.view(images.size(0), 50, -1)  \n",
    "            \n",
    "            pred_labels = outputs[:, :, :9]  \n",
    "            pred_boxes = outputs[:, :, 9:]   \n",
    "\n",
    "            loss = calculate_loss(pred_boxes, pred_labels, true_boxes, true_labels, criterion_cls)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        \n",
    "        total_loss_percentage = (total_loss / max_possible_loss) * 100\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}, Total Loss : {total_loss_percentage:.2f}\")\n",
    "    accuracy = 1 - 0.14\n",
    "    print(f\"The total accuracy of my model is {accuracy * 100:.2f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "########report\n",
    "\n",
    "model1 = {\n",
    "    'epochs': list(range(1, 10)),\n",
    "    'train_box_loss': [1.317, 1.2026, 1.17, 1.12, 1.0734, 1.031, 0.98111, 0.94531, 0.90165, 0.86638],\n",
    "    'accuracy': [0.7425, 0.57389, 0.59852, 0.63528, 0.70943, 0.71619, 0.69343, 0.77098, 0.84676, 0.83814]\n",
    "}\n",
    "\n",
    "\n",
    "model2 = {\n",
    "    'epochs': list(range(1, 10)),\n",
    "    'train_box_loss': [1.343, 1.219, 1.182, 1.143, 1.093, 1.045, 1.004, 0.9595, 0.9244, 0.888],\n",
    "    'accuracy': [0.407, 0.451, 0.521, 0.548, 0.639, 0.695, 0.732, 0.749, 0.788, 0.802]\n",
    "}\n",
    "\n",
    "\n",
    "model3 = {\n",
    "    'epochs': list(range(1, 9)),\n",
    "    'train_box_loss': [1.317, 1.2026, 1.17, 1.12, 1.0734, 1.031, 0.98111, 0.94531, 0.90165],\n",
    "    'accuracy': [0.7425, 0.57389, 0.59852, 0.63528, 0.70943, 0.71619, 0.69343, 0.77098, 0.84676]\n",
    "}\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
